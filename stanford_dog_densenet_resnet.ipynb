{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T17:13:40.007655Z",
     "start_time": "2017-11-13T17:13:39.931932Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "\n",
    "def reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir,\n",
    "                   valid_ratio):\n",
    "    # 读取训练数据标签。\n",
    "    with open(os.path.join(data_dir, label_file), 'r') as f:\n",
    "        # 跳过文件头行（栏名称）。\n",
    "        lines = f.readlines()[1:]\n",
    "        tokens = [l.rstrip().split(',') for l in lines]\n",
    "        idx_label = dict(((idx, label) for idx, label in tokens))\n",
    "    labels = set(idx_label.values())\n",
    "\n",
    "    num_train = len(os.listdir(os.path.join(data_dir, train_dir)))\n",
    "    # 训练集中数量最少一类的狗的数量。\n",
    "    min_num_train_per_label = (\n",
    "        Counter(idx_label.values()).most_common()[:-2:-1][0][1])\n",
    "    # 验证集中每类狗的数量。\n",
    "    num_valid_per_label = math.floor(min_num_train_per_label * valid_ratio)\n",
    "    label_count = dict()\n",
    "\n",
    "    def mkdir_if_not_exist(path):\n",
    "        if not os.path.exists(os.path.join(*path)):\n",
    "            os.makedirs(os.path.join(*path))\n",
    "\n",
    "    # 整理训练和验证集。\n",
    "    for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
    "        idx = train_file.split('.')[0]\n",
    "        label = idx_label[idx]\n",
    "        mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
    "        shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                    os.path.join(data_dir, input_dir, 'train_valid', label))\n",
    "        if label not in label_count or label_count[label] < num_valid_per_label:\n",
    "            mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'valid', label))\n",
    "            label_count[label] = label_count.get(label, 0) + 1\n",
    "        else:\n",
    "            mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'train', label))\n",
    "\n",
    "    # 整理测试集。\n",
    "    mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
    "    for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
    "        shutil.copy(os.path.join(data_dir, test_dir, test_file),\n",
    "                    os.path.join(data_dir, input_dir, 'test', 'unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T06:06:54.621061Z",
     "start_time": "2017-11-19T06:06:54.610032Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reorg_dog_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d34764ee641a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mvalid_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir,\n\u001b[0m\u001b[0;32m      9\u001b[0m                valid_ratio)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reorg_dog_data' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = 'kaggle_dog'\n",
    "label_file = 'labels.csv'\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "input_dir = 'train_valid_test'\n",
    "batch_size = 256\n",
    "valid_ratio = 0.1\n",
    "reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir,\n",
    "               valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T17:49:10.939647Z",
     "start_time": "2017-11-19T17:49:10.290467Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon.data import vision\n",
    "import numpy as np\n",
    "\n",
    "def transform_train(data, label):\n",
    "    #im = data.asnumpy()\n",
    "    #im = np.pad(im, ((4, 4), (4, 4), (0, 0)), mode='constant', constant_values=0)\n",
    "    #im = image.imresize(data.astype('float32') / 255, 96, 96)\n",
    "    im = data.astype('float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 224, 224), resize=256,\n",
    "                        rand_crop=True, rand_resize=True, rand_mirror=True,\n",
    "                        mean=np.array([0.485, 0.456, 0.406]),\n",
    "                        std=np.array([0.229, 0.224, 0.225]),\n",
    "                        brightness=0, contrast=0,\n",
    "                        saturation=0, hue=0,\n",
    "                        pca_noise=0.01, rand_gray=0, inter_method=2)\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    # 将数据格式从\"高*宽*通道\"改为\"通道*高*宽\"。\n",
    "    im = nd.transpose(im, (2,0,1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))\n",
    "\n",
    "def transform_test(data, label):\n",
    "    #im = image.imresize(data.astype('float32') / 255, 96, 96)\n",
    "    im = data.astype('float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 224, 224), resize=256,\n",
    "                        mean=np.array([0.485, 0.456, 0.406]),\n",
    "                        std=np.array([0.229, 0.224, 0.225]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2,0,1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T17:49:12.006338Z",
     "start_time": "2017-11-19T17:49:11.746079Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'kaggle_dog'\n",
    "label_file = 'labels.csv'\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "input_dir = 'train_valid_test'\n",
    "batch_size = 16\n",
    "valid_ratio = 0.1\n",
    "\n",
    "input_str = data_dir + '/' + input_dir + '/'\n",
    "\n",
    "# 读取原始图像文件。flag=1说明输入图像有三个通道（彩色）。\n",
    "train_ds = vision.ImageFolderDataset(input_str + 'train', flag=1,\n",
    "                                     transform=transform_train)\n",
    "valid_ds = vision.ImageFolderDataset(input_str + 'valid', flag=1,\n",
    "                                     transform=transform_test)\n",
    "train_valid_ds = vision.ImageFolderDataset(input_str + 'train_valid',\n",
    "                                           flag=1, transform=transform_train)\n",
    "test_ds = vision.ImageFolderDataset(input_str + 'test', flag=1,\n",
    "                                     transform=transform_test)\n",
    "\n",
    "loader = gluon.data.DataLoader\n",
    "train_data = loader(train_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data = loader(valid_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "train_valid_data = loader(train_valid_ds, batch_size, shuffle=True,\n",
    "                          last_batch='keep')\n",
    "test_data = loader(test_ds, batch_size, shuffle=False, last_batch='keep')\n",
    "\n",
    "# 交叉熵损失函数。\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T17:49:12.544605Z",
     "start_time": "2017-11-19T17:49:12.473409Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "def get_loss(data, net, ctx):\n",
    "    loss = 0.0\n",
    "    for feas, label in data:\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(feas.as_in_context(ctx))\n",
    "        cross_entropy = softmax_cross_entropy(output, label)\n",
    "        loss += nd.mean(cross_entropy).asscalar()\n",
    "    return loss / len(data)\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_period,\n",
    "          lr_decay):\n",
    "    trainer = gluon.Trainer(\n",
    "        net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': 0.9,\n",
    "                                      'wd': wd})\n",
    "    # 确保net的初始化在ctx上\n",
    "    net.collect_params().reset_ctx(ctx)\n",
    "    net.hybridize()\n",
    "    prev_time = datetime.datetime.now()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        if epoch > 0 and (epoch == lr_period or epoch == int(lr_period * 1.5) or epoch ==lr_period*2):\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for data, label in train_data:\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net(data.as_in_context(ctx))\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_loss = get_loss(valid_data, net, ctx)\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, Valid loss %f, \"\n",
    "                         % (epoch, train_loss / len(train_data), valid_loss))\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, \"\n",
    "                         % (epoch, train_loss / len(train_data)))\n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T17:53:17.147522Z",
     "start_time": "2017-11-19T17:53:16.505442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=2208),\n",
       " Activation(relu),\n",
       " AvgPool2D(size=(7, 7), stride=(7, 7), padding=(0, 0), ceil_mode=False),\n",
       " Flatten]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use pretrained models\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "import mxnet as mx\n",
    "ctx = mx.gpu()\n",
    "pretrained_net = models.densenet161(pretrained=True, ctx = ctx) \n",
    "#['DenseNet', 'densenet121', 'densenet161', 'densenet169', 'densenet201']\n",
    "#['VGG','vgg11', 'vgg13', 'vgg16', 'vgg19', 'vgg11_bn', 'vgg13_bn', 'vgg16_bn', 'vgg19_bn', 'get_vgg']\n",
    "#['ResNetV1', 'ResNetV2', 'BasicBlockV1', 'BasicBlockV2', 'BottleneckV1', 'BottleneckV2', 'resnet18_v1', 'resnet34_v1', 'resnet50_v1', 'resnet101_v1', 'resnet152_v1',\n",
    "#           'resnet18_v2', 'resnet34_v2', 'resnet50_v2', 'resnet101_v2', 'resnet152_v2', 'get_resnet']\n",
    "\n",
    "#net = gluon.model_zoo.vision.resnet152_v2(classes=120)\n",
    "(pretrained_net.features[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T17:56:06.163885Z",
     "start_time": "2017-11-19T17:56:06.131297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (1, 3, 224, 224)\n",
      "HybridSequential(\n",
      "  (0): Conv2D(3 -> 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=96)\n",
      "  (2): Activation(relu)\n",
      "  (3): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(1, 1), ceil_mode=False)\n",
      "  (4): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=96)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(96 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=144)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(144 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(192 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=240)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(240 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=288)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(288 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=336)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(336 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (5): HybridSequential(\n",
      "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=384)\n",
      "    (1): Activation(relu)\n",
      "    (2): Conv2D(384 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): AvgPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (6): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(192 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=240)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(240 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=288)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(288 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=336)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(336 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=384)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(384 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=432)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(432 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=480)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(480 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (7): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=528)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(528 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (8): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=576)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(576 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (9): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=624)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(624 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (10): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=672)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(672 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (11): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=720)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(720 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (7): HybridSequential(\n",
      "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=768)\n",
      "    (1): Activation(relu)\n",
      "    (2): Conv2D(768 -> 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): AvgPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (8): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=384)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(384 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=432)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(432 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=480)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(480 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=528)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(528 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=576)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(576 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=624)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(624 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=672)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(672 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (7): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=720)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(720 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (8): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=768)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(768 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (9): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=816)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(816 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (10): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=864)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(864 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (11): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=912)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(912 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (12): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=960)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(960 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (13): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1008)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1008 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (14): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1056)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1056 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (15): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1104)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1104 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (16): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1152)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1152 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (17): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1200)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1200 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (18): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1248)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1248 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (19): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1296)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1296 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (20): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1344)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1344 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (21): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1392)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1392 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (22): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1440)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1440 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (23): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1488)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1488 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (24): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1536)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1536 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (25): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1584)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1584 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (26): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1632)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1632 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (27): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1680)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1680 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (28): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1728)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1728 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (29): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1776)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1776 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (30): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1824)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1824 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (31): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1872)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1872 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (32): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1920)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1920 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (33): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1968)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1968 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (34): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=2016)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(2016 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (35): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=2064)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(2064 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (9): HybridSequential(\n",
      "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=2112)\n",
      "    (1): Activation(relu)\n",
      "    (2): Conv2D(2112 -> 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): AvgPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (10): HybridSequential(\n",
      "    (0): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1056)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1056 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1104)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1104 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1152)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1152 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1200)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1200 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1248)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1248 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1296)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1296 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1344)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1344 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (7): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1392)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1392 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (8): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1440)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1440 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (9): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1488)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1488 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (10): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1536)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1536 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (11): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1584)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1584 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (12): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1632)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1632 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (13): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1680)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1680 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (14): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1728)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1728 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (15): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1776)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1776 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (16): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1824)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1824 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (17): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1872)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1872 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (18): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1920)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1920 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (19): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=1968)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(1968 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (20): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=2016)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(2016 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (21): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=2064)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(2064 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (22): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=2112)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(2112 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (23): HybridConcurrent(\n",
      "      (0): Identity(\n",
      "      \n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=2160)\n",
      "        (1): Activation(relu)\n",
      "        (2): Conv2D(2160 -> 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=192)\n",
      "        (4): Activation(relu)\n",
      "        (5): Conv2D(192 -> 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (11): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=2208)\n",
      "  (12): Activation(relu)\n",
      "  (13): AvgPool2D(size=(7, 7), stride=(7, 7), padding=(0, 0), ceil_mode=False)\n",
      ")\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b1158398d46c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[1;34m\"\"\"Calls forward. Only accepts positional arguments.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m    496\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_cached_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\nn\\basic_layers.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[1;34m(self, F, x)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhybrid_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[1;34m\"\"\"Calls forward. Only accepts positional arguments.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m    489\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_cached_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m                     \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mDeferredInitializationError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_finish_deferred_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    489\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_cached_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m                     \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mDeferredInitializationError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_finish_deferred_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\parameter.py\u001b[0m in \u001b[0;36mdata\u001b[1;34m(self, ctx)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[0mNDArray\u001b[0m \u001b[0mon\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \"\"\"\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_and_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlist_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\parameter.py\u001b[0m in \u001b[0;36m_check_and_get\u001b[1;34m(self, arr_list, ctx)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                     \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ctx_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_typeid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0marr_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import nn\n",
    "net = nn.HybridSequential()\n",
    "for layer in pretrained_net.features[:-1]:\n",
    "    net.add(layer)\n",
    "    \n",
    "input_shape = (224, 224)\n",
    "x = nd.random.uniform(shape=(1,3,*input_shape))\n",
    "print('Input:', x.shape)\n",
    "print(net)\n",
    "print('Output:', net(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Dense(120)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T15:57:55.377276Z",
     "start_time": "2017-11-19T15:57:55.306443Z"
    }
   },
   "outputs": [],
   "source": [
    "net = models.densenet161(classes=120, ctx=ctx)\n",
    "net.collect_params().initialize(init.Xavier(), ctx=ctx)\n",
    "net.features = pretrained_net.features\n",
    "#net.output.initialize(init.Xavier(), ctx=ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T17:49:20.554054Z",
     "start_time": "2017-11-19T17:49:20.543999Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HybridSequential' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6f9cbdfc6f46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#for _, w in net.collect_params().items():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#    w.grad_req = 'null'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_mult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HybridSequential' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "#固定参数\n",
    "#for _, w in net.collect_params().items():\n",
    "#    w.grad_req = 'null'\n",
    "for _, i in net.features.collect_params().items():\n",
    "    i.lr_mult = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T17:49:27.449736Z",
     "start_time": "2017-11-19T17:49:25.539520Z"
    }
   },
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "Shape inconsistent, Provided=[16], inferred shape=[16,2208,1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-cdd95c7b024d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m train(net, train_data, valid_data, num_epochs, learning_rate,\n\u001b[1;32m---> 19\u001b[1;33m       weight_decay, ctx, lr_period, lr_decay)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-1e0ef00d65d7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_period, lr_decay)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_in_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[1;34m\"\"\"Calls forward. Only accepts positional arguments.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m    496\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_cached_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\loss.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[1;34m(self, F, pred, label, sample_weight)\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_label\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reshape_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\ndarray\\register.py\u001b[0m in \u001b[0;36mpick\u001b[1;34m(data, index, axis, keepdims, out, name, **kwargs)\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\_ctypes\\ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[1;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mc_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mc_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\software\\anaconda\\envs\\gluon\\lib\\site-packages\\mxnet\\base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \"\"\"\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMXNetError\u001b[0m: Shape inconsistent, Provided=[16], inferred shape=[16,2208,1]"
     ]
    }
   ],
   "source": [
    "ctx = utils.try_gpu()\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "weight_decay = 1e-4\n",
    "lr_period = 50\n",
    "lr_decay = 0.1\n",
    "\n",
    "#finetune_densenet161.hybridize()\n",
    "\n",
    "#net = get_net(ctx)\n",
    "#net.hybridize()\n",
    "\n",
    "#net = DenseNet(growthRate=12, depth=100, reduction=0.5,\n",
    "#                            bottleneck=True, nClasses=120)\n",
    "#net.hybridize()\n",
    "#net.initialize(ctx=mx.gpu())\n",
    "\n",
    "train(net, train_data, valid_data, num_epochs, learning_rate,\n",
    "      weight_decay, ctx, lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-16T14:53:53.891564Z",
     "start_time": "2017-11-16T14:53:53.676022Z"
    }
   },
   "outputs": [],
   "source": [
    "#filename = \"densenet_depth100.params\"\n",
    "filename = 'resnet50_v2.params'\n",
    "net.save_params(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T14:50:28.854415Z",
     "start_time": "2017-11-19T14:48:25.980732Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#net = get_net(ctx)\n",
    "#net.hybridize()\n",
    "#train(net, train_valid_data, None, num_epochs, learning_rate, weight_decay,\n",
    "#      ctx, lr_period, lr_decay)\n",
    "\n",
    "outputs = []\n",
    "for data, label in test_data:\n",
    "    output = nd.softmax(net(data.as_in_context(ctx)))\n",
    "    outputs.extend(output.asnumpy())\n",
    "ids = sorted(os.listdir(os.path.join(data_dir, input_dir, 'test/unknown')))\n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.write('id,' + ','.join(train_valid_ds.synsets) + '\\n')\n",
    "    for i, output in zip(ids, outputs):\n",
    "        f.write(i.split('.')[0] + ',' + ','.join(\n",
    "            [str(num) for num in output]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
