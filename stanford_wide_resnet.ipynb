{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T16:36:16.851684Z",
     "start_time": "2017-11-27T16:36:16.229093Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\software\\anaconda\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon.data import vision\n",
    "import numpy as np\n",
    "\n",
    "def transform_train(data, label):\n",
    "    #im = data.asnumpy()\n",
    "    #im = np.pad(im, ((4, 4), (4, 4), (0, 0)), mode='constant', constant_values=0)\n",
    "    #im = image.imresize(data.astype('float32') / 255, 96, 96)\n",
    "    im = data.astype('float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 224, 224), resize=256,\n",
    "                        rand_crop=True, rand_resize=True, rand_mirror=True,\n",
    "                        mean=np.array([0.485, 0.456, 0.406]),\n",
    "                        std=np.array([0.229, 0.224, 0.225]),\n",
    "                        brightness=0, contrast=0,\n",
    "                        saturation=0, hue=0,\n",
    "                        pca_noise=0.01, rand_gray=0, inter_method=2)\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    # 将数据格式从\"高*宽*通道\"改为\"通道*高*宽\"。\n",
    "    im = nd.transpose(im, (2,0,1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))\n",
    "\n",
    "def transform_test(data, label):\n",
    "    #im = image.imresize(data.astype('float32') / 255, 96, 96)\n",
    "    im = data.astype('float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 224, 224), resize=256,\n",
    "                        mean=np.array([0.485, 0.456, 0.406]),\n",
    "                        std=np.array([0.229, 0.224, 0.225]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2,0,1))\n",
    "    return (im, nd.array([label]).asscalar().astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T16:36:18.085666Z",
     "start_time": "2017-11-27T16:36:17.859994Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'kaggle_dog'\n",
    "label_file = 'labels.csv'\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "input_dir = 'train_valid_test'\n",
    "batch_size = 8\n",
    "valid_ratio = 0.1\n",
    "\n",
    "input_str = data_dir + '/' + input_dir + '/'\n",
    "\n",
    "# 读取原始图像文件。flag=1说明输入图像有三个通道（彩色）。\n",
    "train_ds = vision.ImageFolderDataset(input_str + 'train', flag=1,\n",
    "                                     transform=transform_train)\n",
    "valid_ds = vision.ImageFolderDataset(input_str + 'valid', flag=1,\n",
    "                                     transform=transform_test)\n",
    "train_valid_ds = vision.ImageFolderDataset(input_str + 'train_valid',\n",
    "                                           flag=1, transform=transform_train)\n",
    "test_ds = vision.ImageFolderDataset(input_str + 'test', flag=1,\n",
    "                                     transform=transform_test)\n",
    "\n",
    "loader = gluon.data.DataLoader\n",
    "train_data = loader(train_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data = loader(valid_ds, batch_size, shuffle=True, last_batch='keep')\n",
    "train_valid_data = loader(train_valid_ds, batch_size, shuffle=True,\n",
    "                          last_batch='keep')\n",
    "test_data = loader(test_ds, batch_size, shuffle=False, last_batch='keep')\n",
    "\n",
    "# 交叉熵损失函数。\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T16:36:19.262187Z",
     "start_time": "2017-11-27T16:36:19.052552Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "def get_loss(data, net, ctx):\n",
    "    loss = 0.0\n",
    "    for feas, label in data:\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(feas.as_in_context(ctx))\n",
    "        cross_entropy = softmax_cross_entropy(output, label)\n",
    "        loss += nd.mean(cross_entropy).asscalar()\n",
    "    return loss / len(data)\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_period,\n",
    "          lr_decay):\n",
    "    trainer = gluon.Trainer(\n",
    "        net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': 0.9,\n",
    "                                      'wd': wd})\n",
    "    # 确保net的初始化在ctx上\n",
    "    net.collect_params().reset_ctx(ctx)\n",
    "    net.hybridize()\n",
    "    prev_time = datetime.datetime.now()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        if epoch > 0 and (epoch == lr_period or epoch == int(lr_period * 1.5) or epoch ==lr_period*2):\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for data, label in train_data:\n",
    "            label = label.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net(data.as_in_context(ctx))\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_loss = get_loss(valid_data, net, ctx)\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, Valid loss %f, \"\n",
    "                         % (epoch, train_loss / len(train_data), valid_loss))\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, \"\n",
    "                         % (epoch, train_loss / len(train_data)))\n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T16:36:20.106414Z",
     "start_time": "2017-11-27T16:36:19.940402Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "\n",
    "class WResidual(nn.HybridBlock):\n",
    "    def __init__(self, channels, same_shape=True, dim_same = True, **kwargs):\n",
    "        super(WResidual, self).__init__(**kwargs)\n",
    "        self.same_shape = same_shape\n",
    "        self.dim_same = dim_same\n",
    "        with self.name_scope():\n",
    "            strides = 1 if same_shape else 2\n",
    "            self.conv1 = nn.Conv2D(channels, kernel_size=3, padding=1,\n",
    "                                  strides=strides)\n",
    "            self.bn1 = nn.BatchNorm()\n",
    "            self.dropout = nn.Dropout(0.3)            \n",
    "            self.conv2 = nn.Conv2D(channels, kernel_size=3, padding=1)            \n",
    "            self.bn2 = nn.BatchNorm()\n",
    "            if not same_shape or not self.dim_same:\n",
    "                self.conv3 = nn.Conv2D(channels, kernel_size=1,\n",
    "                                      strides=strides)\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        out = self.conv1(F.relu(self.bn1((x))))\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        \n",
    "        if not self.same_shape or not self.dim_same:\n",
    "            x = self.conv3(x)\n",
    "        return out + x\n",
    "\n",
    "blocks_per_group = 4\n",
    "widening_factor = 10\n",
    "\n",
    "class wide_ResNet(nn.HybridBlock):\n",
    "    def __init__(self, num_classes, verbose=False, **kwargs):\n",
    "        super(wide_ResNet, self).__init__(**kwargs)\n",
    "        self.verbose = verbose\n",
    "        with self.name_scope():\n",
    "            net = self.net = nn.HybridSequential()\n",
    "            # 模块1\n",
    "            net.add(nn.Conv2D(channels=16, kernel_size=3, strides=1,\n",
    "                              padding=1))\n",
    "            #net.add(nn.BatchNorm())\n",
    "            #net.add(nn.Activation(activation='relu'))\n",
    "            # 模块2\n",
    "            net.add(WResidual(channels=160, same_shape=False))\n",
    "            for _ in range(3):\n",
    "                net.add(WResidual(channels=160))\n",
    "            # 模块3\n",
    "            net.add(WResidual(channels=320, same_shape=False))\n",
    "            for _ in range(3):\n",
    "                net.add(WResidual(channels=320))\n",
    "            # 模块4\n",
    "            net.add(WResidual(channels=640, same_shape=False))\n",
    "            for _ in range(3):\n",
    "                net.add(WResidual(channels=640))\n",
    "            # 模块5\n",
    "            net.add(nn.BatchNorm())\n",
    "            net.add(nn.Activation('relu'))\n",
    "            net.add(nn.GlobalAvgPool2D())\n",
    "            net.add(nn.Flatten())\n",
    "            net.add(nn.Dense(num_classes))\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        out = x\n",
    "        for i, b in enumerate(self.net):\n",
    "            out = b(out)\n",
    "            if self.verbose:\n",
    "                print('Block %d output: %s'%(i+1, out.shape))\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_net(ctx):\n",
    "    num_outputs = 120\n",
    "    net = wide_ResNet(num_outputs)\n",
    "    net.initialize(ctx=ctx, init=init.Xavier())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-27T17:45:11.221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train loss: 4.885599, Valid loss 5.119685, Time 00:22:28, lr 0.01\n"
     ]
    }
   ],
   "source": [
    "ctx = utils.try_gpu()\n",
    "num_epochs = 200\n",
    "learning_rate = 0.01\n",
    "weight_decay = 5e-4\n",
    "lr_period = 80\n",
    "lr_decay = 0.2\n",
    "\n",
    "net = get_net(ctx)\n",
    "net.hybridize()\n",
    "train(net, train_data, valid_data, num_epochs, learning_rate,\n",
    "      weight_decay, ctx, lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
